<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
  
  深度学习 - 不以刷题为目的的面试不是个好程序员
  
  </title>
 <meta name="description" content="面试，刷题，扯淡。。">
 <link href="atom.xml" rel="alternate" title="不以刷题为目的的面试不是个好程序员" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <script src="asset/highlightjs/mermaid.min.js"></script>
    <link href="asset/highlightjs/styles/github-gist.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    <!--add  -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/7.1.0/mermaid.min.js"></script>
    <script>
        var config = {
            startOnLoad:true,
            flowchart:{
                useMaxWidth:false,
                htmlLabels:true
            }
        };
        mermaid.initialize(config);
        $(function(){
            var elements = document.getElementsByClassName("language-mermaid");
            for (var i = elements.length; i--;) {
                element = elements[i];
                var graphDefinition = element.innerText;
                if (graphDefinition) {
                    var svg = mermaid.render('ha_mermaid_' + i, graphDefinition, function(svg){});
                    if (svg) {
                        var svgElement = document.createElement('div');
                        preNode = element.parentNode;
                        svgElement.innerHTML = svg;
                        svgElement.setAttribute('class', 'mermaid');
                        svgElement.setAttribute('data-processed', 'true');
                        preNode.parentNode.replaceChild(svgElement, preNode);
                    }
                }
            }
        });
    </script>
  </head>
  <body class="antialiased hide-extras">

    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">不以刷题为目的的面试不是个好程序员</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 不以刷题为目的的面试不是个好程序员</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>开始瞎扯淡</label></li>

          
            <li><a title="想对自己说的话" href="15406404520470.html">想对自己说的话</a></li>
          
            <li><a title="最近想做的事" href="15392402403847.html">最近想做的事</a></li>
          
            <li><a title="我的偶像" href="15392398597900.html">我的偶像</a></li>
          
            <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
          
            <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
          

      
        <li class="divider"></li>
        <li><label>数据结构</label></li>

          
            <li><a title="文章结构" href="15392326678534.html">文章结构</a></li>
          
            <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
          
            <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
          
            <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
          
            <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
          
            <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
          
            <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
          
            <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
          
            <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法设计</label></li>

          
            <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
          
            <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
          
            <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
          
            <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
          
            <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
          
            <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
          
            <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
          
            <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
          
            <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
          
            <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
          
            <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
          
            <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法思想</label></li>

          
            <li><a title="分治" href="15393053301597.html">分治</a></li>
          
            <li><a title="回溯" href="15393053101796.html">回溯</a></li>
          
            <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
          
            <li><a title="贪心" href="15392704711231.html">贪心</a></li>
          
            <li><a title="递归" href="15392704564412.html">递归</a></li>
          

      
        <li class="divider"></li>
        <li><label>Leetcode</label></li>

          
            <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
          

      
        <li class="divider"></li>
        <li><label>深度学习</label></li>

          
            <li><a title="文本分类TextCNN" href="15434622232762.html">文本分类TextCNN</a></li>
          
            <li><a title="Keras中的数据预处理「文本」" href="15429415402935.html">Keras中的数据预处理「文本」</a></li>
          
            <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
          
            <li><a title="词向量模型及其使用" href="15395247337147.html">词向量模型及其使用</a></li>
          
            <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>机器学习</label></li>

          
            <li><a title="HMM到中文分词" href="15446854936789.html">HMM到中文分词</a></li>
          

      
        <li class="divider"></li>
        <li><label>论文相关</label></li>

          
            <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>公式推导</label></li>

          
            <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>开始瞎扯淡</span></li>
                        
                          <li><a title="想对自己说的话" href="15406404520470.html">想对自己说的话</a></li>
                        
                          <li><a title="最近想做的事" href="15392402403847.html">最近想做的事</a></li>
                        
                          <li><a title="我的偶像" href="15392398597900.html">我的偶像</a></li>
                        
                          <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
                        
                          <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
                        

                    
                      <li class="side-title"><span>数据结构</span></li>
                        
                          <li><a title="文章结构" href="15392326678534.html">文章结构</a></li>
                        
                          <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
                        
                          <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
                        
                          <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
                        
                          <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
                        
                          <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
                        
                          <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
                        
                          <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
                        
                          <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
                        

                    
                      <li class="side-title"><span>算法设计</span></li>
                        
                          <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
                        
                          <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
                        
                          <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
                        
                          <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
                        
                          <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
                        
                          <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
                        
                          <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
                        
                          <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
                        
                          <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
                        
                          <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
                        
                          <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
                        
                          <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
                        

                    
                      <li class="side-title"><span>算法思想</span></li>
                        
                          <li><a title="分治" href="15393053301597.html">分治</a></li>
                        
                          <li><a title="回溯" href="15393053101796.html">回溯</a></li>
                        
                          <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
                        
                          <li><a title="贪心" href="15392704711231.html">贪心</a></li>
                        
                          <li><a title="递归" href="15392704564412.html">递归</a></li>
                        

                    
                      <li class="side-title"><span>Leetcode</span></li>
                        
                          <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
                        

                    
                      <li class="side-title"><span>深度学习</span></li>
                        
                          <li><a title="文本分类TextCNN" href="15434622232762.html">文本分类TextCNN</a></li>
                        
                          <li><a title="Keras中的数据预处理「文本」" href="15429415402935.html">Keras中的数据预处理「文本」</a></li>
                        
                          <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
                        
                          <li><a title="词向量模型及其使用" href="15395247337147.html">词向量模型及其使用</a></li>
                        
                          <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
                        

                    
                      <li class="side-title"><span>机器学习</span></li>
                        
                          <li><a title="HMM到中文分词" href="15446854936789.html">HMM到中文分词</a></li>
                        

                    
                      <li class="side-title"><span>论文相关</span></li>
                        
                          <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
                        

                    
                      <li class="side-title"><span>公式推导</span></li>
                        
                          <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">
 


	
		<div class="markdown-body">
		<h1>文本分类TextCNN</h1>

		<p>about:<a href="https://arxiv.org/abs/1408.5882">《Convolutional Neural Networks for Sentence Classification》</a><br/>
TextCNN即使用卷积神经网络来实现文本分类，CNN经常被用来做图像的分类，而图像在转化成像素点的时候，就变成了一个三维(彩色图片/三通道)的数字矩阵，同样的文本数据在向量化之后也是向量矩阵不过是个一维的/二维的(每个数据的维度取决于向量化的方式)，既然都是数值矩阵，那么是不是也可以像图像一样使用CNN来做呢，这就是TXTCNN要做的事情。</p>

<h1 id="toc_0">TextCNN的网络结构</h1>

<p><img src="media/15434622232762/15487625443034.jpg" alt="" style="width:615px;"/></p>

<p>上图非常清晰的展示了textcnn的整体结构，核心在于4个尺寸的卷积核,对输入数据进行卷积操作之后MaxPool+Flatten操作之后，得到四分数据（一个卷积核一份数据），用一个concat层将四分数据拼接成一份。在接dropout层之后接Dense全连接层进行非线性变换，最后接一层Dense层使用softmax激活函数进行输出分类。</p>

<h1 id="toc_1">TextCNN的优点</h1>

<p>1、首先作为深度学习模型，可以有效的运用预训练词向量带来效果的提升，相比于原始的文本向量化有很大优势<br/>
2、CNN结构本身相比于其他的序列模型在训练上存在速度优势，TextCNN同样。<br/>
3、TextCNN中采用的卷积核长度为词向量维度，多种宽度的组合，等同于N-gram操作，一定程度上保留了词之间的位置特征。</p>

<h1 id="toc_2">TextCNN的keras实现</h1>

<pre class="line-numbers"><code class="language-python">
num_words = 200000
maxlen = 1000  # 1000-&gt;2000
max_features = 200000
embed_size = 200  # 100
num_classes = 20
batch_size = 100
epochs = 100
filter_sizes = [2, 3, 4, 5]  # +6,7
drop_late = 0.1

def build_cnn():
    # Inputs
    input_seq = Input(shape=[maxlen], name=&#39;input_seq&#39;)
    # Embeddings layers
    emb_comment = Embedding(num_words, embed_size, embeddings_initializer=&#39;uniform&#39;,trainable = True)(input_seq)

    # conv layers
    convs = []
    for ks in filter_sizes:
        l_conv = Conv1D(filters=embed_size, kernel_size=ks, activation=&#39;relu&#39;)(emb_comment)
        l_pool = MaxPooling1D(maxlen - ks + 1)(l_conv)
        l_pool = Flatten()(l_pool)
        convs.append(l_pool)
    merge = concatenate(convs, axis=1)

    drop = Dropout(drop_late)(merge)
    Ds1 = Dense(64, activation=&#39;relu&#39;)(drop)
    output = Dense(num_classes, activation=&#39;softmax&#39;)(Ds1)
    model = Model([input_seq], output)
    model.compile(loss=&quot;categorical_crossentropy&quot;, optimizer=&quot;nadam&quot;, metrics=[&#39;acc&#39;])
    # 画出模型结构
    plot_model(model, to_file=&#39;{}.png&#39;.format(path_model))
    # 输出模型结构
    print(model.summary())
    return model

def fit_cnn(model, X, y):
    &quot;&quot;&quot;&quot;&quot;&quot;
    # callback
    early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;,
                                   patience=5)
    checkpoint = ModelCheckpoint(path_model,
                                 monitor=&#39;val_acc&#39;,
                                 verbose=1,
                                 save_best_only=True,
                                 mode=&#39;max&#39;)
    TB_plot = TensorBoard(log_dir=&#39;data/logs&#39;,
                          batch_size=100,
                          write_images=True)
    # fit
    hist = model.fit(X, y, validation_split=0.2,
                     batch_size=batch_size,
                     epochs=epochs,
                     shuffle=True,
                     callbacks=[early_stopping, checkpoint, TB_plot])

    bst_fit_loss = min(hist.history[&#39;loss&#39;])
    bst_fit_acc = max(hist.history[&#39;acc&#39;])

    bst_val_loss = min(hist.history[&#39;val_loss&#39;])
    bst_val_acc = max(hist.history[&#39;val_acc&#39;])

    print(
        &quot;bst_fit_loss:{}\nbst_fit_acc:{}\nbst_val_loss:{}\nbst_val_acc:{}&quot;.format(bst_fit_loss, bst_fit_acc,
                                                                                  bst_val_loss,
                                                                                  bst_val_acc))
    return model
</code></pre>

<h1 id="toc_3">调参</h1>

<p>参照：<a href="https://arxiv.org/pdf/1510.03820.pdf">&lt;<A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification>&gt;</a>textcnn调参指南。<br/>
其实可以调整的参数不多，主要是卷积核的组合，dropout的失活率，其实更多的提升还是来自于对文本的处理和业务、任务的理解上。结合预训练词向量。</p>

<h1 id="toc_4">总结：</h1>

<p>TextCNN算是文本分类里面最简单也最易理解的模型，因为本身cnn就比较好理解，主要是在于理解卷积操作，在图像和文本上的差异，图像上卷积核更灵活，文本上卷积核长度必须是词向量长度，因为卷积核最小也必须覆盖一个字符。否则就会把一个字符的词向量拆开。</p>


		</div>
	

 
	

 
	

 
	

 
	

  
  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
