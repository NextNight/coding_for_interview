<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
  
  HMM到中文分词 - 不以刷题为目的的面试不是个好程序员
  
  </title>
 <meta name="description" content="面试，刷题，扯淡。。">
 <link href="atom.xml" rel="alternate" title="不以刷题为目的的面试不是个好程序员" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <script src="asset/highlightjs/mermaid.min.js"></script>
    <link href="asset/highlightjs/styles/github-gist.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    <!--add  -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/7.1.0/mermaid.min.js"></script>
    <script>
        var config = {
            startOnLoad:true,
            flowchart:{
                useMaxWidth:false,
                htmlLabels:true
            }
        };
        mermaid.initialize(config);
        $(function(){
            var elements = document.getElementsByClassName("language-mermaid");
            for (var i = elements.length; i--;) {
                element = elements[i];
                var graphDefinition = element.innerText;
                if (graphDefinition) {
                    var svg = mermaid.render('ha_mermaid_' + i, graphDefinition, function(svg){});
                    if (svg) {
                        var svgElement = document.createElement('div');
                        preNode = element.parentNode;
                        svgElement.innerHTML = svg;
                        svgElement.setAttribute('class', 'mermaid');
                        svgElement.setAttribute('data-processed', 'true');
                        preNode.parentNode.replaceChild(svgElement, preNode);
                    }
                }
            }
        });
    </script>
  </head>
  <body class="antialiased hide-extras">

    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">不以刷题为目的的面试不是个好程序员</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 不以刷题为目的的面试不是个好程序员</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>数据结构</label></li>

          
            <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
          
            <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
          
            <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
          
            <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
          
            <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
          
            <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
          
            <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
          
            <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法设计</label></li>

          
            <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
          
            <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
          
            <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
          
            <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
          
            <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
          
            <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
          
            <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
          
            <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
          
            <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
          
            <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
          
            <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
          
            <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法思想</label></li>

          
            <li><a title="时间复杂度与空间复杂度" href="15500647845613.html">时间复杂度与空间复杂度</a></li>
          
            <li><a title="分治" href="15393053301597.html">分治</a></li>
          
            <li><a title="回溯" href="15393053101796.html">回溯</a></li>
          
            <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
          
            <li><a title="贪心" href="15392704711231.html">贪心</a></li>
          
            <li><a title="递归" href="15392704564412.html">递归</a></li>
          

      
        <li class="divider"></li>
        <li><label>Leetcode</label></li>

          
            <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
          

      
        <li class="divider"></li>
        <li><label>深度学习</label></li>

          
            <li><a title="文本分类TextCNN" href="15434622232762.html">文本分类TextCNN</a></li>
          
            <li><a title="Keras中的数据预处理「文本」" href="15429415402935.html">Keras中的数据预处理「文本」</a></li>
          
            <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
          
            <li><a title="词向量模型及其使用" href="15395247337147.html">词向量模型及其使用</a></li>
          
            <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>机器学习</label></li>

          
            <li><a title="HMM到中文分词" href="15446854936789.html">HMM到中文分词</a></li>
          

      
        <li class="divider"></li>
        <li><label>论文相关</label></li>

          
            <li><a title="论文collections" href="15488331878996.html">论文collections</a></li>
          
            <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>公式推导</label></li>

          
            <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
          

      
        <li class="divider"></li>
        <li><label>开始瞎扯淡</label></li>

          
            <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
          
            <li><a title="Plan" href="15392402403847.html">Plan</a></li>
          
            <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>数据结构</span></li>
                        
                          <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
                        
                          <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
                        
                          <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
                        
                          <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
                        
                          <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
                        
                          <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
                        
                          <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
                        
                          <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
                        

                    
                      <li class="side-title"><span>算法设计</span></li>
                        
                          <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
                        
                          <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
                        
                          <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
                        
                          <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
                        
                          <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
                        
                          <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
                        
                          <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
                        
                          <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
                        
                          <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
                        
                          <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
                        
                          <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
                        
                          <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
                        

                    
                      <li class="side-title"><span>算法思想</span></li>
                        
                          <li><a title="时间复杂度与空间复杂度" href="15500647845613.html">时间复杂度与空间复杂度</a></li>
                        
                          <li><a title="分治" href="15393053301597.html">分治</a></li>
                        
                          <li><a title="回溯" href="15393053101796.html">回溯</a></li>
                        
                          <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
                        
                          <li><a title="贪心" href="15392704711231.html">贪心</a></li>
                        
                          <li><a title="递归" href="15392704564412.html">递归</a></li>
                        

                    
                      <li class="side-title"><span>Leetcode</span></li>
                        
                          <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
                        

                    
                      <li class="side-title"><span>深度学习</span></li>
                        
                          <li><a title="文本分类TextCNN" href="15434622232762.html">文本分类TextCNN</a></li>
                        
                          <li><a title="Keras中的数据预处理「文本」" href="15429415402935.html">Keras中的数据预处理「文本」</a></li>
                        
                          <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
                        
                          <li><a title="词向量模型及其使用" href="15395247337147.html">词向量模型及其使用</a></li>
                        
                          <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
                        

                    
                      <li class="side-title"><span>机器学习</span></li>
                        
                          <li><a title="HMM到中文分词" href="15446854936789.html">HMM到中文分词</a></li>
                        

                    
                      <li class="side-title"><span>论文相关</span></li>
                        
                          <li><a title="论文collections" href="15488331878996.html">论文collections</a></li>
                        
                          <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
                        

                    
                      <li class="side-title"><span>公式推导</span></li>
                        
                          <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
                        

                    
                      <li class="side-title"><span>开始瞎扯淡</span></li>
                        
                          <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
                        
                          <li><a title="Plan" href="15392402403847.html">Plan</a></li>
                        
                          <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">
 <div class="markdown-body">
<h1>HMM到中文分词</h1>

<p><img src="media/15446854936789/Merkov_2.gif" alt="Merkov_2"/> <br/>
HMM隐马尔科夫模型一直是个很困扰，感觉上又很难的点，这是一篇个人理解的大白话文，去记录HMM是如何用于中文分词的。上面这张图展示的就是一个序列生成的过程，也是一个马尔科夫决策过程。这里说的是<code>「马尔科夫」</code>并不是<code>「隐马尔科夫」</code>。</p>

<h1 id="toc_0">MM(马尔科夫)到HMM(隐马尔科夫)</h1>

<p>上图中有两个状态：R，S,R状态可以变转变为S状态，R也可以转变为R，S也可以转变为S，加入一开始我们以某种概率选择一种状态R或者S，然后以这个状态为初始不断地选择下一个状态，这样就形成了一个观察到的状态序列，我们叫做<strong>观测序列</strong>。我们发现这个观测序列中的每一个状态都是状态集中的一种。那同样的当我们没办法直接观察到原始状态的时候，我们就说我们想得到的<strong>状态序列</strong>是隐藏的。这就是「HMM(隐马尔科夫)」。而我们能观测到的观测序列是另一种状态，比如说r,s。简单来说：</p>

<pre class="line-numbers"><code class="language-text"> MM:(R,S)——&gt;R,R,S,S,S,S,R,S....状态==观测
 
HMM:(R,S)——&gt;?,?,?,?,?,?,?,?....状态(隐)
            r,s,r,s,s,s,r,s....观测
</code></pre>

<p>这就是MM和HMM的区别。</p>

<h1 id="toc_1">HMM中不得不说的五元组</h1>

<p>开始的图中已经提到了<code>状态集</code>，<code>观测集</code>，而生成不同的序列取决于各个状态之间的<code>转移概率矩阵</code>,上图就是以如下的转移矩阵进行状态转换的：</p>

<table>
<thead>
<tr>
<th>转移概率</th>
<th>R</th>
<th>S</th>
</tr>
</thead>

<tbody>
<tr>
<td>R</td>
<td>0.9</td>
<td>0.1</td>
</tr>
<tr>
<td>S</td>
<td>0.1</td>
<td>0.9</td>
</tr>
</tbody>
</table>

<p>当无法观测到状态序列的时候，状态序列和观测序列之间就存在一种概率关系，即：当观测为r时，状态为s的概率。这种概率关系计做<code>发射概率矩阵</code>如下：</p>

<table>
<thead>
<tr>
<th>发射概率</th>
<th>r</th>
<th>s</th>
</tr>
</thead>

<tbody>
<tr>
<td>R</td>
<td>0.8</td>
<td>0.2</td>
</tr>
<tr>
<td>S</td>
<td>0.1</td>
<td>0.9</td>
</tr>
</tbody>
</table>

<p>而最后一个就是<code>初始状态分布</code>,他决定了序列的开始，而开始总是结果有着一定的影响，那么他到底是如何影响的呢，这就与HMM的数学假设有关了。</p>

<h1 id="toc_2">HMM的三个基本假设</h1>

<p>数学中经常会用到很多的假设，因为在真实环境中影响问题的因素多种多样，假设通常用来简化问题，从而找到问题的解法。否则很多问题将无法求解。</p>

<ul>
<li><strong>有限历史性假设</strong>：当前的状态取决于他前那一刻状态，这就为什么初始分布会对对状态序列有影响了。</li>
<li><strong>输出独立性假设</strong>：输出仅与当前状态有关，换句话说：观测序列当前值仅与其对应的状态序列当前值有关，再简单点来说：t时刻观测到r还是s,仅取决于t时刻状态时R还是S。</li>
<li><strong>齐次性假设</strong>：每个时刻的状态取决于前一刻的状态，而与时间没有关系。简单来说：状态不受时间影响。
有了假设，有了HMM核心的五元组就可以解决三个问题，这其中就包括中文分词。</li>
</ul>

<h1 id="toc_3">HMM解决的三大问题</h1>

<ul>
<li><strong>1、求解观察值序列</strong>：给定HMM其他的四元组求解一个观察序列的概率，采用前向算法</li>
<li><strong>2、求解状态值序列</strong>：给定HMM其他的四元组求解一个最有可能生成观测序列的状态序列。 如：<code>中文分词</code>，<code>语音识别</code>，采用<code>Viterbi</code>算法</li>
<li><strong>3、学习HMM模型</strong>：已知观测序列，去学习HMM模型,采用</li>
</ul>

<h1 id="toc_4">中文分词的解决方案</h1>

<p>如上所述：中文分词就是HMM模型+一句话(观测序列)+viterbi算法去求解状态值序列。而中文分词的状态值序列就是一个状态集（B,E,M,S）的序列，S:单字成词，B:一个词的开头，E:一个词的结尾，M：一个词的中间。</p>

<blockquote>
<p>比如说：<code>我喜欢秦皇岛的阳光</code>这句话，我们得到一个最可能的状态序列：SBEBMESBE.这个状态序列表示的就是分词的结果，因此得到的分词结果就是：<code>我/喜欢/秦皇岛/的/阳光</code></p>
</blockquote>

<p>这里面有两个问题：</p>

<ul>
<li>HMM模型怎么来的？-&gt;预训练模型</li>
<li>如何求解状态序列？-&gt;&#39;viterbi算法&#39;</li>
</ul>

<p>也就是说我们的分词算法调用一个已经训练好的HMM模型加上‘viterbi算法’就可以实现中文分词,如下图：<img src="media/15446854936789/cutchinese.png" alt="cutchinese"/></p>

<h1 id="toc_5">中文分词的Viterbi算法</h1>

<blockquote>
<p>Viterbi算法是一种<code>动态规划算法</code>，动态规范算法通常是用来求解最优化问题，而在中文分词中则用来求解最大化观测序列概率的状态序列。也就是说求解一个状态序列使得到的观测序列无限的接近于我们看到的序列。</p>
</blockquote>

<p>以上面的<strong>「我喜欢秦皇岛的阳光」</strong>为例，只有当我们生成的序列是「SBEBMESBE」的时候，生成<strong>『我喜欢秦皇岛的阳光』</strong>句子的概率才达到最大。此时『SBEBMESBE』就是我们要求的状态序列。为了方便后面的描述和代码下面更加精确的定义五元组：</p>

<ol>
<li>状态集：O(B,S,E,M)</li>
<li>观测集：S(我，喜，欢，秦，皇，岛，的，阳，光)</li>
<li>初始概率分布：PS(0.4,0.6,0,0)</li>
<li><p>转移概率矩阵:当前时刻状态为某个值的时候下一刻状态为某个值得概率</p>
<table>
<thead>
<tr>
<th></th>
<th>S</th>
<th>B</th>
<th>M</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr>
<td>S</td>
<td>0.5</td>
<td>0.5</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>B</td>
<td>0</td>
<td>0</td>
<td>0.5</td>
<td>0.5</td>
</tr>
<tr>
<td>M</td>
<td>0</td>
<td>0</td>
<td>0.5</td>
<td>0.5</td>
</tr>
<tr>
<td>E</td>
<td>0.4</td>
<td>0.6</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table></li>
<li><p>发射概率矩阵:状态为某个值的时候观测到某个值得概率</p>
<table>
<thead>
<tr>
<th></th>
<th>我</th>
<th>喜</th>
<th>欢</th>
<th>秦</th>
<th>皇</th>
<th>导</th>
<th>的</th>
<th>阳</th>
<th>光</th>
</tr>
</thead>
<tbody>
<tr>
<td>S</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table></li>
</ol>

<p>有了如上的五元组，我们就可以用Viterbi算法解出最可能的状态序列。以下是jieba分词中的Viterbi实现，参数就是五元组，</p>

<pre class="line-numbers"><code class="language-python">&#39;&#39;&#39;jieba分词中的Viterbi实现&#39;&#39;&#39;
def viterbi(obs, states, start_p, trans_p, emit_p):
    V = [{}]  # tabular
    path = {}
    for y in states:  # init
        V[0][y] = start_p[y] + emit_p[y].get(obs[0], MIN_FLOAT)
        path[y] = [y]
    for t in xrange(1, len(obs)):
        V.append({})
        newpath = {}
        for y in states:
            em_p = emit_p[y].get(obs[t], MIN_FLOAT)
            (prob, state) = max(
                [(V[t - 1][y0] + trans_p[y0].get(y, MIN_FLOAT) + em_p, y0) for y0 in PrevStatus[y]])
            V[t][y] = prob
            newpath[y] = path[state] + [y]
        path = newpath

    (prob, state) = max((V[len(obs) - 1][y], y) for y in &#39;ES&#39;)
    return (prob, path[state])
</code></pre>

<blockquote>
<p>核心部分就是从第一个时刻开始(即顺序遍历观测集)，对于每一个时刻(每一个观测值)计算出得到这个观测值最大概率P,和对应的状态值，有了这个概率和状态值，就可以求得下一时刻的最大概率P和对应的状态值，知道遍历完这个观测值序列，我们就得到了一个值得最终概率最大的状态值序列，而这个序列就是我们所求的。(每一时刻的最大不代表全局最大，我们要找的是全局概率最大的路径。)</p>
</blockquote>

<h1 id="toc_6">其他问题</h1>

<p>当状态值是『B S E M』的时候，HMM可以用来做中文分词，同样的当状态值是『n,v,...』等词性的时候，HMM就可以用来解决词性标注的问题。同样的命名实体识别的问题也可以这样解决。</p>

<blockquote>
<p>HMM中当假设当前时刻状态只与前一刻状态相关的时候，我们称之为“一阶隐马尔科夫模型”，当假设当前时刻状态与前两刻状态有关的时候我们称之为“二阶隐马”。介数越高，复杂度越高，计算量越大，同时越接近真实的语言场景。</p>
</blockquote>


</div>

<br /><br />
<hr />

<div class="row clearfix">
  <div class="large-6 columns">
	<div class="text-left" style="padding:15px 0px;">
		
	        <a href="15395241741886.html"  title="Previous Post: 文本分类模型">&laquo; 文本分类模型</a>
	    
	</div>
  </div>
  <div class="large-6 columns">
	<div class="text-right" style="padding:15px 0px;">
		
	        <a href="15488331878996.html" 
	        title="Next Post: 论文collections">论文collections &raquo;</a>
	    
	</div>
  </div>
</div>

<div class="row">
<div style="padding:0px 0.93em;" class="share-comments">

</div>
</div>
<script type="text/javascript">
	$(function(){
		var currentURL = '15446854936789.html';
		$('#side-nav a').each(function(){
			if($(this).attr('href') == currentURL){
				$(this).parent().addClass('active');
			}
		});
	});
</script>  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
