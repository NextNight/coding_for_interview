<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
  
  深度学习库keras - 不以刷题为目的的面试不是个好程序员
  
  </title>
 <meta name="description" content="面试，刷题，扯淡。。">
 <link href="atom.xml" rel="alternate" title="不以刷题为目的的面试不是个好程序员" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <script src="asset/highlightjs/mermaid.min.js"></script>
    <link href="asset/highlightjs/styles/github-gist.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    <!--add  -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/7.1.0/mermaid.min.js"></script>
    <script>
        var config = {
            startOnLoad:true,
            flowchart:{
                useMaxWidth:false,
                htmlLabels:true
            }
        };
        mermaid.initialize(config);
        $(function(){
            var elements = document.getElementsByClassName("language-mermaid");
            for (var i = elements.length; i--;) {
                element = elements[i];
                var graphDefinition = element.innerText;
                if (graphDefinition) {
                    var svg = mermaid.render('ha_mermaid_' + i, graphDefinition, function(svg){});
                    if (svg) {
                        var svgElement = document.createElement('div');
                        preNode = element.parentNode;
                        svgElement.innerHTML = svg;
                        svgElement.setAttribute('class', 'mermaid');
                        svgElement.setAttribute('data-processed', 'true');
                        preNode.parentNode.replaceChild(svgElement, preNode);
                    }
                }
            }
        });
    </script>
  </head>
  <body class="antialiased hide-extras">

    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">不以刷题为目的的面试不是个好程序员</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 不以刷题为目的的面试不是个好程序员</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>数据结构</label></li>

          
            <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
          
            <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
          
            <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
          
            <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
          
            <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
          
            <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
          
            <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
          
            <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法设计</label></li>

          
            <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
          
            <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
          
            <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
          
            <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
          
            <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
          
            <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
          
            <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
          
            <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
          
            <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
          
            <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
          
            <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
          
            <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法思想</label></li>

          
            <li><a title="时间复杂度与空间复杂度" href="15500647845613.html">时间复杂度与空间复杂度</a></li>
          
            <li><a title="分治" href="15393053301597.html">分治</a></li>
          
            <li><a title="回溯" href="15393053101796.html">回溯</a></li>
          
            <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
          
            <li><a title="贪心" href="15392704711231.html">贪心</a></li>
          
            <li><a title="递归" href="15392704564412.html">递归</a></li>
          

      
        <li class="divider"></li>
        <li><label>Leetcode</label></li>

          
            <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
          

      
        <li class="divider"></li>
        <li><label>深度学习</label></li>

          
            <li><a title="文本分类TextCNN" href="15434622232762.html">文本分类TextCNN</a></li>
          
            <li><a title="Keras中的数据预处理「文本」" href="15429415402935.html">Keras中的数据预处理「文本」</a></li>
          
            <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
          
            <li><a title="词向量模型及其使用" href="15395247337147.html">词向量模型及其使用</a></li>
          
            <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>机器学习</label></li>

          
            <li><a title="HMM到中文分词" href="15446854936789.html">HMM到中文分词</a></li>
          

      
        <li class="divider"></li>
        <li><label>论文相关</label></li>

          
            <li><a title="论文collections" href="15488331878996.html">论文collections</a></li>
          
            <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>公式推导</label></li>

          
            <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
          

      
        <li class="divider"></li>
        <li><label>开始瞎扯淡</label></li>

          
            <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
          
            <li><a title="Plan" href="15392402403847.html">Plan</a></li>
          
            <li><a title="speaking self" href="15406404520470.html">speaking self</a></li>
          
            <li><a title="我的偶像" href="15392398597900.html">我的偶像</a></li>
          
            <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>数据结构</span></li>
                        
                          <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
                        
                          <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
                        
                          <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
                        
                          <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
                        
                          <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
                        
                          <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
                        
                          <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
                        
                          <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
                        

                    
                      <li class="side-title"><span>算法设计</span></li>
                        
                          <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
                        
                          <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
                        
                          <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
                        
                          <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
                        
                          <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
                        
                          <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
                        
                          <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
                        
                          <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
                        
                          <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
                        
                          <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
                        
                          <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
                        
                          <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
                        

                    
                      <li class="side-title"><span>算法思想</span></li>
                        
                          <li><a title="时间复杂度与空间复杂度" href="15500647845613.html">时间复杂度与空间复杂度</a></li>
                        
                          <li><a title="分治" href="15393053301597.html">分治</a></li>
                        
                          <li><a title="回溯" href="15393053101796.html">回溯</a></li>
                        
                          <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
                        
                          <li><a title="贪心" href="15392704711231.html">贪心</a></li>
                        
                          <li><a title="递归" href="15392704564412.html">递归</a></li>
                        

                    
                      <li class="side-title"><span>Leetcode</span></li>
                        
                          <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
                        

                    
                      <li class="side-title"><span>深度学习</span></li>
                        
                          <li><a title="文本分类TextCNN" href="15434622232762.html">文本分类TextCNN</a></li>
                        
                          <li><a title="Keras中的数据预处理「文本」" href="15429415402935.html">Keras中的数据预处理「文本」</a></li>
                        
                          <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
                        
                          <li><a title="词向量模型及其使用" href="15395247337147.html">词向量模型及其使用</a></li>
                        
                          <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
                        

                    
                      <li class="side-title"><span>机器学习</span></li>
                        
                          <li><a title="HMM到中文分词" href="15446854936789.html">HMM到中文分词</a></li>
                        

                    
                      <li class="side-title"><span>论文相关</span></li>
                        
                          <li><a title="论文collections" href="15488331878996.html">论文collections</a></li>
                        
                          <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
                        

                    
                      <li class="side-title"><span>公式推导</span></li>
                        
                          <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
                        

                    
                      <li class="side-title"><span>开始瞎扯淡</span></li>
                        
                          <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
                        
                          <li><a title="Plan" href="15392402403847.html">Plan</a></li>
                        
                          <li><a title="speaking self" href="15406404520470.html">speaking self</a></li>
                        
                          <li><a title="我的偶像" href="15392398597900.html">我的偶像</a></li>
                        
                          <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">
 <div class="markdown-body">
<h1>深度学习库keras</h1>

<pre class="line-numbers"><code class="language-mermaid">graph LR;
  数据处理--&gt;模型训练;
  模型训练--&gt;模型优化;
</code></pre>

<p>深度学习整个的流程跟机器学习没什么差别，主要的区别在模型上，深度神经网络更复杂，更加多变，能力更强，「 简单快读的入门方式就是找到体系的流程快读的实现demo。而这个流程的一些问题和阻碍，以及应该注意的地方是我这里想说的。」</p>

<h1 id="toc_0">keras相关的模块</h1>

<p>涉及到机器学习总是离不开几个关键词<code>『数据』</code>，<code>『模型』</code>，<code>『评估函数』</code>，<code>『损失函数』</code>。同样的深度学习也以这几个关键词为基础。keras以主流的深度学习库为后端构建了简单易用的上层API以便我们使用。包括数据处理，评估函数，损失函数的实现，更是提供了各种网络层的实现和封装，通过简单的函数API和序列API进行各种网络层的堆叠就可以实现各式各样的神经网络结构。</p>

<h2 id="toc_1">keras的预处理模块</h2>

<p><code>from keras.preprocessing import sequence,text,image</code></p>

<ul>
<li>image：图像相关</li>
<li>sequence：序列相关</li>
<li>text：文本相关</li>
</ul>

<h2 id="toc_2">keras的Utils</h2>

<p>keras的utils模块主要是提供建模流程的各种辅助操作，其中包括数据相关的，IO相关的，数据操作相关，网络层相关的操作具体如下：</p>

<pre class="line-numbers"><code class="language-python">from .io_utils import HDF5Matrix
from .data_utils import get_file
from .data_utils import Sequence
from .data_utils import GeneratorEnqueuer
from .data_utils import OrderedEnqueuer
from .generic_utils import CustomObjectScope
from .generic_utils import custom_object_scope
from .generic_utils import get_custom_objects
from .generic_utils import serialize_keras_object
from .generic_utils import deserialize_keras_object
from .generic_utils import Progbar
from .layer_utils import convert_all_kernels_in_model
from .layer_utils import print_summary
from .vis_utils import plot_model
from .np_utils import to_categorical
from .np_utils import normalize
from .multi_gpu_utils import multi_gpu_model
</code></pre>

<p>而常用的主要是：<code>from keras.utils import np_utils, plot_model</code></p>

<ul>
<li>np_utils：
<ul>
<li>to_categorical：进行类别编码</li>
<li>normalize：正则化</li>
</ul></li>
<li>plot_model:用与画出模型结构</li>
</ul>

<h2 id="toc_3">keras的Models</h2>

<p>keras的models模块主要是实现模型相关的操作：</p>

<ul>
<li>load_model：模型加载，可以加在已经保存的训练好的模型直接用于预测</li>
<li>save_model：模型保存，可以讲训练好的模型进行保存</li>
<li>Sequential：顺序模型，可以直接使用此函数构建一个模型网络，顺序模型是多个网络层的线性堆叠。</li>
</ul>

<pre class="line-numbers"><code class="language-python">from keras.models import Sequential
from keras.layers import Dense, Activation
model = Sequential([
    Dense(32, input_shape=(784,)),
    Activation(&#39;relu&#39;),
    Dense(10),
    Activation(&#39;softmax&#39;),
])
&#39;&#39;&#39;或&#39;&#39;&#39;
model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Activation(&#39;relu&#39;))
model.add(Dense(10))
model.add(Activation(&#39;softmax&#39;))
</code></pre>

<h2 id="toc_4">keras的losses</h2>

<p>losses即损失函数，也可以叫做目标函数，优化评分函数，它用来告诉我们模型该如何调整到最优，keras中的losses 实现如下：</p>

<pre class="line-numbers"><code class="language-python">回归
    mse = MSE = mean_squared_error
    mae = MAE = mean_absolute_error
    mape = MAPE = mean_absolute_percentage_error
    msle = MSLE = mean_squared_logarithmic_error
    kld = KLD = kullback_leibler_divergence
    cosine = cosine_proximity
分类
    categorical_crossentropy：多分
    binary_crossentropy：二分
    sparse_categorical_crossentropy
。。。
</code></pre>

<p>对于不同的问题需要选择不同的损失函数，二分勒，多分类，回归都需要不同的损失函数，模型才能正常训练。</p>

<h2 id="toc_5">keras的metrics</h2>

<p>评估函数是用来评估模型效果，与loss有很多公用的函数，keras中的metrics实现如下：</p>

<pre class="line-numbers"><code class="language-python">误差：
    mse = MSE = mean_squared_error
    mae = MAE = mean_absolute_error
    mape = MAPE = mean_absolute_percentage_error
    msle = MSLE = mean_squared_logarithmic_error
    cosine = cosine_proximity
准确率：
    binary_accuracy:
    categorical_accuracy
    sparse_categorical_accuracy
。。。
</code></pre>

<blockquote>
<p>如果没有我们需要的评价函数的话就需要自定义评价函数如：f1_score</p>
</blockquote>

<pre class="line-numbers"><code class="language-python">def f1_score(y_true, y_pred):
    # Count positive samples.
    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))
    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))
    # If there are no true samples, fix the F1 score at 0.
    if c3 == 0:
        return 0
    # How many selected items are relevant?
    precision = c1 / c2
    # How many relevant items are selected?
    recall = c1 / c3
    # Calculate f1_score
    f1_score = 2 * (precision * recall) / (precision + recall)
    return f1_score
</code></pre>

<h2 id="toc_6">keras的「optimizer」优化器</h2>

<p>optermizer优化器是用来根据误差不断调整参数使得目标函数预测值不断接近真实值的一种计算方法。耳熟能详的<code>梯度下降</code>就是其一，其他的还有牛顿法，共轭梯度法，keras中的优化器如下：</p>

<pre class="line-numbers"><code class="language-python">sgd = SGD
rmsprop = RMSprop
adagrad = Adagrad
adadelta = Adadelta
adam = Adam
adamax = Adamax
nadam = Nadam
</code></pre>

<h2 id="toc_7">keras的callback</h2>

<p>callback回调函数是用于在模型训练过程中对模型活着数据进行操作，最常用的是：</p>

<pre class="line-numbers"><code class="language-python">ModelCheckpoint:训练的过程中不断的保存模型，是一种容错机制。
EarlyStopping:提前停止，一种降低训练时间和过拟合的策略。
</code></pre>

<h2 id="toc_8">keras的layers「网络层」</h2>

<p>0、嵌入层</p>

<pre class="line-numbers"><code class="language-python">Embedding:
</code></pre>

<p>1、核心层：</p>

<pre class="line-numbers"><code class="language-python">Input:输入层，用于实例化Keras张量。
Dense：全链接层
Activation：激活函数
Dropout：随机失活，防止过拟合
Faltten:输入展平
Reshape：修改尺寸
Permute：纬度置换
RepeatVector：重复输入数据
Lambda：将表达式封装为一个层，即自定义层
ActivityRegularization：正则化
Masking：
SpatialDropout1D
SpatialDropout2D
SpatialDropout3D
</code></pre>

<p>2、卷积层：构成卷积神经网络的基础</p>

<pre class="line-numbers"><code class="language-python">Conv1D:一维卷积
Conv2D:二维卷积
Conv3D:三维卷积

UpSampling1D:1D 输入的上采样层。
UpSampling2D:2D 输入的上采样层。
UpSampling3D:3D 输入的上采样层。
。。。
</code></pre>

<p>3、循环层：循环神经网路的基础</p>

<pre class="line-numbers"><code class="language-python">RNN 
SimpleRNN
GRU
Lstm 
</code></pre>

<p>4、池化层：</p>

<pre class="line-numbers"><code class="language-python">最大池化层
    MaxPooling1D
    MaxPooling2D
    MaxPooling3D
平均池化层：
    AveragePooling1D
    AveragePooling2D
    AveragePooling3D
全局最大池化层
    GlobalMaxPooling1D
    GlobalMaxPooling2D
    GlobalMaxPooling3D
全局平均池化层：
    GlobalAveragePooling1D
    GlobalAveragePooling2D
    GlobalAveragePooling3D
</code></pre>

<p>5、融合层：两个/多个层的数据进行某种计算进行融合</p>

<pre class="line-numbers"><code class="language-python">Add:逐元素相加
Subtract:逐元素相减
Multiply：逐元素相乘
Average：逐元素平均
Maximum：逐元素最大值
Concatenate：按轴拼接
Dot：点积
</code></pre>

<p>6、噪声层：缓解过拟合</p>

<pre class="line-numbers"><code class="language-python">GaussianNoise:高斯噪声
GaussianDropout:
AlphaDropout:
</code></pre>

<p>7、层封装器</p>

<pre class="line-numbers"><code class="language-python">TimeDistributed:
Bidirectional:RNN的双向封装器，对序列进行前向和后向计算。
</code></pre>

<p>8、激活函数：用于对数据进行非线性变换</p>

<pre class="line-numbers"><code class="language-python">sigmoid
softmax
hard_sigmoid
linear:线性激活函数（即不做任何改变）
elu:指数线性单元。
selu:可伸缩的指数线性单元（SELU）。
relu:线性修正单元。
tanh:双曲正切激活函数。
softplus:log(exp(x) + 1)
softsign:x / (abs(x) + 1)
</code></pre>


</div>

<br /><br />
<hr />

<div class="row clearfix">
  <div class="large-6 columns">
	<div class="text-left" style="padding:15px 0px;">
		
	        <a href="15429415402935.html"  title="Previous Post: Keras中的数据预处理「文本」">&laquo; Keras中的数据预处理「文本」</a>
	    
	</div>
  </div>
  <div class="large-6 columns">
	<div class="text-right" style="padding:15px 0px;">
		
	        <a href="15395247337147.html" 
	        title="Next Post: 词向量模型及其使用">词向量模型及其使用 &raquo;</a>
	    
	</div>
  </div>
</div>

<div class="row">
<div style="padding:0px 0.93em;" class="share-comments">

</div>
</div>
<script type="text/javascript">
	$(function(){
		var currentURL = '15421840556162.html';
		$('#side-nav a').each(function(){
			if($(this).attr('href') == currentURL){
				$(this).parent().addClass('active');
			}
		});
	});
</script>  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
