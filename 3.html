<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
  
  深度学习 - 不以刷题为目的的面试不是个好程序员
  
  </title>
 <meta name="description" content="面试，刷题，扯淡。。">
 <link href="atom.xml" rel="alternate" title="不以刷题为目的的面试不是个好程序员" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <script src="asset/highlightjs/mermaid.min.js"></script>
    <link href="asset/highlightjs/styles/github-gist.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    <!--add  -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/7.1.0/mermaid.min.js"></script>
    <script>
        var config = {
            startOnLoad:true,
            flowchart:{
                useMaxWidth:false,
                htmlLabels:true
            }
        };
        mermaid.initialize(config);
        $(function(){
            var elements = document.getElementsByClassName("language-mermaid");
            for (var i = elements.length; i--;) {
                element = elements[i];
                var graphDefinition = element.innerText;
                if (graphDefinition) {
                    var svg = mermaid.render('ha_mermaid_' + i, graphDefinition, function(svg){});
                    if (svg) {
                        var svgElement = document.createElement('div');
                        preNode = element.parentNode;
                        svgElement.innerHTML = svg;
                        svgElement.setAttribute('class', 'mermaid');
                        svgElement.setAttribute('data-processed', 'true');
                        preNode.parentNode.replaceChild(svgElement, preNode);
                    }
                }
            }
        });
    </script>
  </head>
  <body class="antialiased hide-extras">

    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">不以刷题为目的的面试不是个好程序员</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 不以刷题为目的的面试不是个好程序员</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>开始瞎扯淡</label></li>

          
            <li><a title="最想说的话" href="15406404520470.html">最想说的话</a></li>
          
            <li><a title="最近想做的事" href="15392402403847.html">最近想做的事</a></li>
          
            <li><a title="我的偶像" href="15392398597900.html">我的偶像</a></li>
          
            <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
          
            <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
          

      
        <li class="divider"></li>
        <li><label>数据结构</label></li>

          
            <li><a title="文章结构" href="15392326678534.html">文章结构</a></li>
          
            <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
          
            <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
          
            <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
          
            <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
          
            <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
          
            <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
          
            <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
          
            <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法设计</label></li>

          
            <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
          
            <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
          
            <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
          
            <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
          
            <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
          
            <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
          
            <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
          
            <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
          
            <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
          
            <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
          
            <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
          
            <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
          

      
        <li class="divider"></li>
        <li><label>算法思想</label></li>

          
            <li><a title="分治" href="15393053301597.html">分治</a></li>
          
            <li><a title="回溯" href="15393053101796.html">回溯</a></li>
          
            <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
          
            <li><a title="贪心" href="15392704711231.html">贪心</a></li>
          
            <li><a title="递归" href="15392704564412.html">递归</a></li>
          

      
        <li class="divider"></li>
        <li><label>Leetcode</label></li>

          
            <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
          

      
        <li class="divider"></li>
        <li><label>深度学习</label></li>

          
            <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
          
            <li><a title="词向量模型" href="15395247337147.html">词向量模型</a></li>
          
            <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>论文相关</label></li>

          
            <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
          

      
        <li class="divider"></li>
        <li><label>公式推导</label></li>

          
            <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>开始瞎扯淡</span></li>
                        
                          <li><a title="最想说的话" href="15406404520470.html">最想说的话</a></li>
                        
                          <li><a title="最近想做的事" href="15392402403847.html">最近想做的事</a></li>
                        
                          <li><a title="我的偶像" href="15392398597900.html">我的偶像</a></li>
                        
                          <li><a title="吴翼：我的ACM参赛故事" href="15391808991416.html">吴翼：我的ACM参赛故事</a></li>
                        
                          <li><a title="我这一生" href="15391740524915.html">我这一生</a></li>
                        

                    
                      <li class="side-title"><span>数据结构</span></li>
                        
                          <li><a title="文章结构" href="15392326678534.html">文章结构</a></li>
                        
                          <li><a title="堆：Heap" href="15392363328863.html">堆：Heap</a></li>
                        
                          <li><a title="图：Graph" href="15392292553953.html">图：Graph</a></li>
                        
                          <li><a title="哈希表：Hash" href="15392292427453.html">哈希表：Hash</a></li>
                        
                          <li><a title="树：Tree" href="15392291769523.html">树：Tree</a></li>
                        
                          <li><a title="栈：Stack" href="15392291360952.html">栈：Stack</a></li>
                        
                          <li><a title="队列：Queue" href="15391808453198.html">队列：Queue</a></li>
                        
                          <li><a title="链表：LinkedList" href="15391807987921.html">链表：LinkedList</a></li>
                        
                          <li><a title="数组：Array" href="15391804069666.html">数组：Array</a></li>
                        

                    
                      <li class="side-title"><span>算法设计</span></li>
                        
                          <li><a title="查找问题" href="15393054098142.html">查找问题</a></li>
                        
                          <li><a title="二分查找" href="15395253854404.html">二分查找</a></li>
                        
                          <li><a title="排序问题" href="15392700147620.html">排序问题</a></li>
                        
                          <li><a title="计数排序" href="15392716754828.html">计数排序</a></li>
                        
                          <li><a title="希尔排序" href="15392716677172.html">希尔排序</a></li>
                        
                          <li><a title="桶排序" href="15392715483846.html">桶排序</a></li>
                        
                          <li><a title="归并排序" href="15392715143262.html">归并排序</a></li>
                        
                          <li><a title="快速排序" href="15392714966006.html">快速排序</a></li>
                        
                          <li><a title="冒泡排序" href="15392714719077.html">冒泡排序</a></li>
                        
                          <li><a title="插入排序" href="15392697680749.html">插入排序</a></li>
                        
                          <li><a title="Markdown语法" href="15391839924703.html">Markdown语法</a></li>
                        
                          <li><a title="选择排序" href="15391804641073.html">选择排序</a></li>
                        

                    
                      <li class="side-title"><span>算法思想</span></li>
                        
                          <li><a title="分治" href="15393053301597.html">分治</a></li>
                        
                          <li><a title="回溯" href="15393053101796.html">回溯</a></li>
                        
                          <li><a title="动态规划" href="15392704829367.html">动态规划</a></li>
                        
                          <li><a title="贪心" href="15392704711231.html">贪心</a></li>
                        
                          <li><a title="递归" href="15392704564412.html">递归</a></li>
                        

                    
                      <li class="side-title"><span>Leetcode</span></li>
                        
                          <li><a title="Twonumsum" href="15392386512557.html">Twonumsum</a></li>
                        

                    
                      <li class="side-title"><span>深度学习</span></li>
                        
                          <li><a title="深度学习库keras" href="15421840556162.html">深度学习库keras</a></li>
                        
                          <li><a title="词向量模型" href="15395247337147.html">词向量模型</a></li>
                        
                          <li><a title="文本分类模型" href="15395241741886.html">文本分类模型</a></li>
                        

                    
                      <li class="side-title"><span>论文相关</span></li>
                        
                          <li><a title="文本分类的注意力模型" href="15395117974496.html">文本分类的注意力模型</a></li>
                        

                    
                      <li class="side-title"><span>公式推导</span></li>
                        
                          <li><a title="逻辑回归" href="15392705055223.html">逻辑回归</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">
 


	
		<div class="markdown-body">
		<h1>深度学习库keras</h1>

		<h2 id="toc_0">深度学习的流程</h2>

<pre class="line-numbers"><code class="language-mermaid">graph TD;
  数据处理--&gt;模型训练;
  模型训练--&gt;模型优化;
</code></pre>

<p>深度学习整个的流程跟机器学习没什么差别，主要的区别在模型上，深度神经网络更复杂，更加多变，能力更强，<br/>
「 简单快读的入门方式就是找到体系的流程快读的实现demo。而这个流程的一些问题和阻碍，以及应该注意的地方是我这里想说的。 」。</p>

<h2 id="toc_1">keras相关的模块</h2>

<p>涉及到机器学习总是离不开几个关键词<code>『数据』</code>，<code>『模型』</code>，<code>『评估函数』</code>，<code>『损失函数』</code>。同样的深度学习也以这几个关键词为基础。keras以主流的深度学习库为后端构建了简单易用的上层API以便我们使用。包括数据处理，评估函数，损失函数的实现，更是提供了各种网络层的实现和封装，通过简单的函数API和序列API进行各种网络层的堆叠就可以实现各式各样的神经网络结构。</p>

<h3 id="toc_2">keras的预处理模块</h3>

<p><code>from keras.preprocessing import sequence,text,image</code></p>

<ul>
<li>image：图像相关</li>
<li>sequence：序列相关</li>
<li>text：文本相关<br/>
### keras的Utils<br/>
keras的utils模块主要是提供建模流程的各种辅助操作，其中包括数据相关的，IO相关的，数据操作相关，网络层相关的操作具体如下：
<code>
from .io_utils import HDF5Matrix<br/>
from .data_utils import get_file<br/>
from .data_utils import Sequence<br/>
from .data_utils import GeneratorEnqueuer<br/>
from .data_utils import OrderedEnqueuer<br/>
from .generic_utils import CustomObjectScope<br/>
from .generic_utils import custom_object_scope<br/>
from .generic_utils import get_custom_objects<br/>
from .generic_utils import serialize_keras_object<br/>
from .generic_utils import deserialize_keras_object<br/>
from .generic_utils import Progbar<br/>
from .layer_utils import convert_all_kernels_in_model<br/>
from .layer_utils import print_summary<br/>
from .vis_utils import plot_model<br/>
from .np_utils import to_categorical<br/>
from .np_utils import normalize<br/>
from .multi_gpu_utils import multi_gpu_model
</code>
而常用的主要是：<code>from keras.utils import np_utils, plot_model,</code></li>
<li>np_utils：
<ul>
<li>to_categorical：进行类别编码</li>
<li>normalize：正则化</li>
</ul></li>
<li>plot_model:用与画出模型结构<br/>
### keras的Models<br/>
keras的models模块主要是实现模型相关的操作：</li>
<li>load_model：模型加载，可以加在已经保存的训练好的模型直接用于预测</li>
<li>save_model：模型保存，可以讲训练好的模型进行保存</li>
<li>Sequential：顺序模型，可以直接使用此函数构建一个模型网络，顺序模型是多个网络层的线性堆叠。
<code>python
from keras.models import Sequential<br/>
from keras.layers import Dense, Activation<br/>
model = Sequential([<br/>
Dense(32, input_shape=(784,)),<br/>
Activation(&#39;relu&#39;),<br/>
Dense(10),<br/>
Activation(&#39;softmax&#39;),<br/>
])<br/>
&#39;&#39;&#39;或&#39;&#39;&#39;<br/>
model = Sequential()<br/>
model.add(Dense(32, input_dim=784))<br/>
model.add(Activation(&#39;relu&#39;))<br/>
model.add(Dense(10))<br/>
model.add(Activation(&#39;softmax&#39;))
</code>
### keras的losses<br/>
losses即损失函数，也可以叫做目标函数，优化评分函数，它用来告诉我们模型该如何调整到最优，keras中的losses 实现如下：
<code>python
回归<br/>
mse = MSE = mean_squared_error<br/>
mae = MAE = mean_absolute_error<br/>
mape = MAPE = mean_absolute_percentage_error<br/>
msle = MSLE = mean_squared_logarithmic_error<br/>
kld = KLD = kullback_leibler_divergence<br/>
cosine = cosine_proximity<br/>
分类<br/>
categorical_crossentropy：多分<br/>
binary_crossentropy：二分<br/>
sparse_categorical_crossentropy<br/>
。。。
</code>
对于不同的问题需要选择不同的损失函数，二分勒，多分类，回归都需要不同的损失函数，模型才能正常训练。<br/>
### keras的metrics<br/>
评估函数是用来评估模型效果，与loss有很多公用的函数，keras中的metrics实现如下：
<code>python
误差：<br/>
mse = MSE = mean_squared_error<br/>
mae = MAE = mean_absolute_error<br/>
mape = MAPE = mean_absolute_percentage_error<br/>
msle = MSLE = mean_squared_logarithmic_error<br/>
cosine = cosine_proximity<br/>
准确率：<br/>
binary_accuracy:<br/>
categorical_accuracy<br/>
sparse_categorical_accuracy<br/>
。。。
</code>
&gt; 如果没有我们需要的评价函数的话就需要自定义评价函数如：f1_score
<code>python
def f1_score(y_true, y_pred):<br/>
# Count positive samples.<br/>
c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))<br/>
c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))<br/>
c3 = K.sum(K.round(K.clip(y_true, 0, 1)))<br/>
# If there are no true samples, fix the F1 score at 0.<br/>
if c3 == 0:<br/>
    return 0<br/>
# How many selected items are relevant?<br/>
precision = c1 / c2<br/>
# How many relevant items are selected?<br/>
recall = c1 / c3<br/>
# Calculate f1_score<br/>
f1_score = 2 * (precision * recall) / (precision + recall)<br/>
return f1_score
</code>
### keras的「optimizer」优化器<br/>
optermizer优化器是用来根据误差不断调整参数使得目标函数预测值不断接近真实值的一种计算方法。耳熟能详的<code>梯度下降</code>就是其一，其他的还有牛顿法，共轭梯度法，keras中的优化器如下：
<code>python
sgd = SGD<br/>
rmsprop = RMSprop<br/>
adagrad = Adagrad<br/>
adadelta = Adadelta<br/>
adam = Adam<br/>
adamax = Adamax<br/>
nadam = Nadam
</code> 
### keras的callback<br/>
callback回调函数是用于在模型训练过程中对模型活着数据进行操作，最常用的是：
<code>
ModelCheckpoint:训练的过程中不断的保存模型，是一种容错机制。<br/>
EarlyStopping:提前停止，一种降低训练时间和过拟合的策略。
</code>
### keras的layers「网络层」<br/>
0、嵌入层
<code>
Embedding:
</code>
1、核心层：
<code>
Input:输入层，用于实例化Keras张量。<br/>
Dense：全链接层<br/>
Activation：激活函数<br/>
Dropout：随机失活，防止过拟合<br/>
Faltten:输入展平<br/>
Reshape：修改尺寸<br/>
Permute：纬度置换<br/>
RepeatVector：重复输入数据<br/>
Lambda：将表达式封装为一个层，即自定义层<br/>
ActivityRegularization：正则化<br/>
Masking：<br/>
SpatialDropout1D<br/>
SpatialDropout2D<br/>
SpatialDropout3D
</code>
2、卷基层：构成卷积神经网络的基础<br/>
```<br/>
Conv1D:一维卷积<br/>
Conv2D:二维卷积<br/>
Conv3D:三维卷积</li>
</ul>

<p>UpSampling1D:1D 输入的上采样层。<br/>
UpSampling2D:2D 输入的上采样层。<br/>
UpSampling3D:3D 输入的上采样层。<br/>
。。。</p>

<pre class="line-numbers"><code class="language-text">3、循环层：循环神经网路的基础
</code></pre>

<p>RNN <br/>
SimpleRNN<br/>
GRU<br/>
Lstm </p>

<pre class="line-numbers"><code class="language-text">4、池化层：
</code></pre>

<p>最大池化层<br/>
    MaxPooling1D<br/>
    MaxPooling2D<br/>
    MaxPooling3D<br/>
平均池化层：<br/>
    AveragePooling1D<br/>
    AveragePooling2D<br/>
    AveragePooling3D<br/>
全局最大池化层<br/>
    GlobalMaxPooling1D<br/>
    GlobalMaxPooling2D<br/>
    GlobalMaxPooling3D<br/>
全局平均池化层：<br/>
    GlobalAveragePooling1D<br/>
    GlobalAveragePooling2D<br/>
    GlobalAveragePooling3D</p>

<pre class="line-numbers"><code class="language-text">5、融合层：两个/多个层的数据进行某种计算进行融合
</code></pre>

<p>Add:逐元素相加<br/>
Subtract:逐元素相减<br/>
Multiply：逐元素相乘<br/>
Average：逐元素平均<br/>
Maximum：逐元素最大值<br/>
Concatenate：按轴拼接<br/>
Dot：点积</p>

<pre class="line-numbers"><code class="language-text">6、噪声层：缓解过拟合
</code></pre>

<p>GaussianNoise:高斯噪声<br/>
GaussianDropout:<br/>
AlphaDropout:</p>

<pre class="line-numbers"><code class="language-text">7、层封装器
</code></pre>

<p>TimeDistributed:<br/>
Bidirectional;RNN的双向封装器，对序列进行前向和后向计算。</p>

<pre class="line-numbers"><code class="language-text">8、激活函数：用于对数据进行非线性变换
</code></pre>

<p>sigmoid<br/>
softmax<br/>
hard_sigmoid<br/>
linear:线性激活函数（即不做任何改变）<br/>
elu:指数线性单元。<br/>
selu:可伸缩的指数线性单元（SELU）。<br/>
relu:线性修正单元。<br/>
tanh:双曲正切激活函数。<br/>
softplus:log(exp(x) + 1)<br/>
softsign:x / (abs(x) + 1)</p>

<pre class="line-numbers"><code class="language-text">







</code></pre>


		</div>
	

 
	

 
	

  
  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
